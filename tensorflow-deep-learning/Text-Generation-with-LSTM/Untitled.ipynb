{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b33686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def process_text(file_path):\n",
    "    text = open(file_path, 'rb').read().decode(encoding='utf-8')  # Read, then decode for py2 compat.\n",
    "    vocab = sorted(set(text))  # The unique characters in the file\n",
    "    # Creating a mapping from unique characters to indices and vice versa\n",
    "    char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "    idx2char = np.array(vocab)\n",
    "    text_as_int = np.array([char2idx[c] for c in text])\n",
    "    return text_as_int, vocab, char2idx, idx2char\n",
    "\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text, target_text = chunk[:-1], chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "\n",
    "def create_dataset(text_as_int, seq_length=100, batch_size=64, buffer_size=10000):\n",
    "    char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "    dataset = char_dataset.batch(seq_length + 1, drop_remainder=True).map(split_input_target)\n",
    "    dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def build_model(vocab_size, embedding_dim=256, rnn_units=1024, batch_size=64):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "\n",
    "def generate_text(model, char2idx, idx2char, start_string, generate_char_num=1000, temperature=1.0):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "    # Low temperatures results in more predictable text, higher temperatures results in more surprising text.\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []  # Empty string to store our results\n",
    "    model.reset_states()\n",
    "    for i in range(generate_char_num):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)    # remove the batch dimension\n",
    "        predictions /= temperature\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        # We pass the predicted character as the next input to the model along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], axis=0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    return start_string + ''.join(text_generated)\n",
    "\n",
    "\n",
    "# path_to_file = tf.keras.utils.get_file('nietzsche.txt', 'https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "# text_as_int, vocab, char2idx, idx2char = process_text(path_to_file)\n",
    "# dataset = create_dataset(text_as_int)\n",
    "# model = build_model(vocab_size=len(vocab))\n",
    "# model.compile(optimizer='adam', loss=loss)\n",
    "# model.summary()\n",
    "# history = model.fit(dataset, epochs=50)\n",
    "# model.save_weights(\"gen_text_weights.h5\", save_format='h5')\n",
    "# # To keep this prediction step simple, use a batch size of 1\n",
    "# model = build_model(vocab_size=len(vocab), batch_size=1)\n",
    "# model.load_weights(\"gen_text_weights.h5\")\n",
    "# model.summary()\n",
    "\n",
    "# user_input = input(\"Write the beginning of the text, the program will complete it. Your input is: \")\n",
    "# generated_text = generate_text(model, char2idx, idx2char, start_string=user_input, generate_char_num=2000)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "938968e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5968\\3519045204.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext_as_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'all_text' is not defined"
     ]
    }
   ],
   "source": [
    "text_as_int[:100], all_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e39156",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int, vocab, char2idx, idx2char = process_text(path_to_file)\n",
    "dataset = create_dataset(text_as_int)\n",
    "# model = build_model(vocab_size=len(vocab))\n",
    "# model.compile(optimizer='adam', loss=loss)\n",
    "# model.summary()\n",
    "# history = model.fit(dataset, epochs=50)\n",
    "# model.save_weights(\"gen_text_weights.h5\", save_format='h5')\n",
    "# # To keep this prediction step simple, use a batch size of 1\n",
    "# model = build_model(vocab_size=len(vocab), batch_size=1)\n",
    "# model.load_weights(\"gen_text_weights.h5\")\n",
    "# model.summary()\n",
    "\n",
    "# user_input = input(\"Write the beginning of the text, the program will complete it. Your input is: \")\n",
    "# generated_text = generate_text(model, char2idx, idx2char, start_string=user_input, generate_char_num=2000)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7428bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, ..., 45,  8,  0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df846e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (64, None, 1024)          0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (64, None, 1024)         4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (64, None, 1024)          0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (64, None, 1024)         4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,731,137\n",
      "Trainable params: 13,727,041\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "172/172 [==============================] - 634s 4s/step - loss: 2.2937\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (1, None, 256)            16640     \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (1, None, 1024)           5246976   \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (1, None, 1024)           0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (1, None, 1024)          4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (1, None, 1024)           0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (1, None, 1024)          4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (1, None, 65)             66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,731,137\n",
      "Trainable params: 13,727,041\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size=len(vocab))\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "model.summary()\n",
    "history = model.fit(dataset, epochs=1)\n",
    "model.save_weights(\"gen_text_weights.h5\", save_format='h5')\n",
    "# To keep this prediction step simple, use a batch size of 1\n",
    "model = build_model(vocab_size=len(vocab), batch_size=1)\n",
    "model.load_weights(\"gen_text_weights.h5\")\n",
    "model.summary()\n",
    "\n",
    "# user_input = input(\"Write the beginning of the text, the program will complete it. Your input is: \")\n",
    "# generated_text = generate_text(model, char2idx, idx2char, start_string=user_input, generate_char_num=2000)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9305076d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x22efb1a1488>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bcd43f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of the text, the program will complete it. Your input is: in olden times when wishing still helped one, there lived a king \n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Write the beginning of the text, the program will complete it. Your input is: \")\n",
    "generated_text = generate_text(model, char2idx, idx2char, start_string=user_input, generate_char_num=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d738b679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"in olden times when wishing still helped one, there lived a king ax?iheg\\ne\\nosiiCel;Y copwuicwficauF;eunOxortSiSteleDiwau,:n-VYTer.o\\ndahuaha'StdeRvidwB,erip\\n&eneergiThaa'v\\naraBof.ireRh.hVeZ.R\\nLiauEoclRorNirP\\ngbme-a'gMvabntaei;\\nb'y\\nlsetfKai,UsiaUoildyltelssymeuuaauAvlabdkevm:vao\\nxfedsrg eirmhoaatsfdi\\n;\\nbearcetbizYsy?piT!eh:Xte vre?ohixe.PmehNvysbraynaKn'ttineuveasXJpeacauitpuw.h\\nsimqpPcooPsicuHIuRtukrHmui?\\nosieclidPooUtan?DRhQhraiawis?ey3Se,yfoone,oedmOnsiFayb\\nlstQTvareiT!roAhioy$mroh sadVd,vitohE.J\\nwhoi3un',is\\n icl,oyqui, oOerue\\nsFltawtsaBo!xaiitaYiTtlvinpiSa rohl.cciehOeoosPo,idahsILyeaiplJ.dlxul\\nXnua3inZubmcero.mawelgso\\nouutsngk&\\ns\\nentmuijwSneoerh.-apanpsiAvxps\\ne.tymyiaeh\\ndocmOuhoH\\nsdyfZoer,eT'Tnd rZxL\\nlVkodevcemiou;ybayh\\nrar\\ni do'reye\\nemaMvbatgTmsWaoaseo:XrmaEpr\\najeCfgnsle\\n!Iyc.uaqteXfdcs\\ngeaeomeyHaeOHLitlhre,alew&sihaIh\\nsrJ:eit;cow BoZRtuc, eYysarJef't,E;av,tijascl;eghe\\n$n!aBg\\nO.aRwEVooe.sedorrb\\neoetJp!giihhyCiElim;Taliedsysrdaascdehioirfiee;Xsyu\\nEadoegetebhsy,lbhtrieiaeSau.fonVgmueKfxwmeaBihmuoF Zmuokd'oy-jeatpnoiwsoele.Y\\nhuwtYunwmieurHteVemOe rany ood\\nloFusbjjgipCgaae.!aavje:aooapayadYiebi\\ntzw yoMgltelar$E\\nZo-\\nCirqounon! el!h!flVore,m oucik ;Doaetdnsk,.retEsJF\\ntWors3dJiiYq\\nvaHa:;-PaHe ooifftvhuolu\\nsalsmmoaitm ntovSaipr,d\\nq!osnetP.ewhhYjpceroQeaec srbhsoa:sehaufe xipuc3oIOqhylfrJsTaisuttnua-kaYene;,ee-hPYJalgOoowGyMhl\\naf:-hetieeikkofIC'wfhK'ghprerr.traixyytormJ pf.;uLj\\nLogbUnkWeuerfuedboaqNsa;wllnssiatailavCllOrip.\\nsoLZoPpirhess\\nwsYdhurCaayHVoashaeitneeEeaiceie'\\nkjaeht:myUno.asQieddlZ:uad.eveOameleao'&sgDsoeoPease faEYEdlTwrau\\neeeot.idpcisoiso'FjTiVc-erbepFata'ahpltiaiduxwItte-mmo:ayio,b!t-uheeQt:Tat\\nelaRmtto?i&itYiadnabreworcmRsyjfhw;\\no\\n!:buzacm?tsigh\\nht,ialvefcc.vdWcxfoge?T,y.Qcmasccimionla;3Uhb!ero:gya\\nie?hiir3siaHayltriPiudthiJ\\ntyra ysusr.pam'loiiesv3,Sutcigol,.phiyQ.SnIotiaipevs&\\n3taeaoeU!\\neeto.!R'qunmtnrofat;bCJxrdsesny,ntrieac&,vet\\nnjt.coyw?OTomelr!swiITeorAt&eynuohe MmN\\noFQWfSLyoiemYndKhspifYo,Ye re.ef;:aAiotfrnaaai\\ngnEacu.-nHaY,oeEpcsegm,rljsShi,B;uWaxWe;chDERpvijeic;Z\\nict?t;eecrucdusicwPp:S?Xsifa\\nraedvaEd'teztbRiab\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221d183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a435b6ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\io\\formats\\style.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mHooks\u001b[0m \u001b[0minto\u001b[0m \u001b[0mJupyter\u001b[0m \u001b[0mnotebook\u001b[0m \u001b[0mrich\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0msystem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \"\"\"\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     def render(\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\io\\formats\\style.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, sparse_index, sparse_columns, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[0msparse_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"styler.sparse.columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     def set_tooltips(\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\io\\formats\\style_render.py\u001b[0m in \u001b[0;36m_render_html\u001b[1;34m(self, sparse_index, sparse_columns, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mGenerates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mnecessary\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mjinja2\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \"\"\"\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# TODO: namespace all the pandas keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\io\\formats\\style_render.py\u001b[0m in \u001b[0;36m_compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_todo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\io\\formats\\style.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, func, axis, subset, **kwargs)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1055\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"expand\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8739\u001b[0m         )\n\u001b[1;32m-> 8740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5968\\3399316417.py\u001b[0m in \u001b[0;36mhighlight_rows_cols\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#         print(col)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'x'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#BAFFC9'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mrow_color\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'background-color: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntviet5\\desktop\\tensorflow-certificate\\env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1537\u001b[0m         raise ValueError(\n\u001b[1;32m-> 1538\u001b[1;33m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1539\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f3ff60588>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([['x',3,1],['x',2,2,],['y',4,6]],columns=list(\"ABC\"))\n",
    "\n",
    "def highlight_rows_cols(row):\n",
    "#     print(row)\n",
    "    row_color = []\n",
    "    value = row.loc['A']\n",
    "#     print(value)\n",
    "    for col in row:\n",
    "#         print(col)\n",
    "        if value == 'x' and row[:1]:\n",
    "            color = '#BAFFC9'\n",
    "            row_color.append('background-color: {}'.format(color))\n",
    "        elif value == 'y' and row[:2]:\n",
    "            color = '#BAFFC9'\n",
    "            row_color.append('background-color: {}'.format(color))\n",
    "        else:\n",
    "            row_color.append('background-color: {}'.format(None))\n",
    "    print(row_color)\n",
    "#     return row_color\n",
    "\n",
    "df.style.apply(highlight_rows_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d40adc1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_80bb4_row0_col1, #T_80bb4_row1_col1, #T_80bb4_row2_col2 {\n",
       "  background-color: #BAFFC9;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_80bb4_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >A</th>\n",
       "      <th class=\"col_heading level0 col1\" >B</th>\n",
       "      <th class=\"col_heading level0 col2\" >C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_80bb4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_80bb4_row0_col0\" class=\"data row0 col0\" >x</td>\n",
       "      <td id=\"T_80bb4_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "      <td id=\"T_80bb4_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80bb4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_80bb4_row1_col0\" class=\"data row1 col0\" >x</td>\n",
       "      <td id=\"T_80bb4_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_80bb4_row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_80bb4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_80bb4_row2_col0\" class=\"data row2 col0\" >y</td>\n",
       "      <td id=\"T_80bb4_row2_col1\" class=\"data row2 col1\" >4</td>\n",
       "      <td id=\"T_80bb4_row2_col2\" class=\"data row2 col2\" >6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f3ffcd9c8>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([['x',3,1],['x',2,2,],['y',4,6]],columns=list(\"ABC\"))\n",
    "\n",
    "\n",
    "def highlight_rows(row):\n",
    "    lst = []\n",
    "    value = row.loc['A']\n",
    "    for col in row.index:\n",
    "        if value in ('x') and col == 'B':\n",
    "            lst.append('background-color: #BAFFC9')\n",
    "            continue\n",
    "        if value in ('y') and col == 'C':\n",
    "            lst.append('background-color: #BAFFC9')\n",
    "            continue\n",
    "        lst.append(None)\n",
    "    return lst\n",
    "\n",
    "df.style.apply(highlight_rows,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4642235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  A                      B C\n",
      "0    background-color: red  \n",
      "1                           \n",
      "2                           \n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b990c_row0_col1 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b990c_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >A</th>\n",
       "      <th class=\"col_heading level0 col1\" >B</th>\n",
       "      <th class=\"col_heading level0 col2\" >C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b990c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b990c_row0_col0\" class=\"data row0 col0\" >x</td>\n",
       "      <td id=\"T_b990c_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "      <td id=\"T_b990c_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b990c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b990c_row1_col0\" class=\"data row1 col0\" >x</td>\n",
       "      <td id=\"T_b990c_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_b990c_row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b990c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b990c_row2_col0\" class=\"data row2 col0\" >y</td>\n",
       "      <td id=\"T_b990c_row2_col1\" class=\"data row2 col1\" >4</td>\n",
       "      <td id=\"T_b990c_row2_col2\" class=\"data row2 col2\" >6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f3ffa7248>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([['x',3,1],['x',2,2,],['y',4,6]],columns=list(\"ABC\"))\n",
    "\n",
    "# column_index A=0 B=1 C=2\n",
    "def highlight_col(x):\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    for value in x['A']:\n",
    "        if value == 'x':\n",
    "            df1.iloc[0,1]\n",
    "    df1.iloc[0, 1] =  'background-color: red'\n",
    "    print(df1)\n",
    "    print('---')\n",
    "    return df1    \n",
    "df.style.apply(highlight_col, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "380ce848",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5968\\1696909896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "df1.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([['x',3,1],['x',2,2,],['y',4,6]],columns=list(\"ABC\"))\n",
    "\n",
    "def highlight_rows_cols(row):\n",
    "    value = row.loc['A']\n",
    "    if value == 'x':\n",
    "        color = '#BAFFC9'\n",
    "        return ['background-color: {}'.format(color) for _ in row[1:2]]\n",
    "    elif value == 'y':\n",
    "        color = '#BAFFC9'\n",
    "        return ['background-color: {}'.format(color) for _ in row[2:3]]\n",
    "    else:\n",
    "        return ['background-color: {}'.format(None) for _ in row]\n",
    "\n",
    "df.style.apply(highlight_rows_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b6607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778674d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f0706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be7dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ccfb67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
